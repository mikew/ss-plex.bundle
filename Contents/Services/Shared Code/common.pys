# Some clients request a certain endpoint
# that doesn't add Contents/Libraries/Shared
# to sys.path. this fixes that.

import re
import inspect, os, sys
d = os.path.abspath( inspect.getfile(inspect.currentframe()) + '/../../../Libraries/Shared' ) # script directory

if not d in sys.path:
    sys.path.insert(0, d)

import ss

HTTP.Headers['Accept-Encoding'] = 'gzip,deflate,identity'

class SSPlexEnvironment(object):
    def css_from_string(self, haystack, selector):
        return HTML.ElementFromString(haystack).cssselect(selector)

    def xpath_from_string(self, haystack, query):
        return HTML.ElementFromString(haystack).xpath(query)

    def json_from_url(self, url, params = {}, expires = 0):
        def get_body():
            return self.body_from_url(url, params = params)

        if expires > 0:
            payload = ss.cache.fetch('%s-json' % url,
                    get_body, expires = expires)
        else:
            payload = get_body()

        return self.json_from_string(payload)

    def json_from_object(self, obj):
        return JSON.StringFromObject(obj)

    def json_from_string(self, string):
        return JSON.ObjectFromString(string)

    def body_from_url(self, url, params = {}):
        return HTTP.Request(url, values = params).content

def restart_channel():
    try:
        # touch Contents/Code/__init__.py
        os.utime(local_path('Contents', 'Code', '__init__.py'), None)
    except Exception, e:
        Log(e)

def init_ss():
    try:
        ss.environment.factory
    except Exception, e:
        cleanup_old_libraries()
        restart_channel()
        import time
        time.sleep(2)
        return

    if ss.environment.factory is ss.environment.default_environment:
        Log('init ss')
        #ss.util.redirect_output(local_path('out'))
        ss.util.log_to_file(ss_logfile)
        ss.environment.factory = SSPlexEnvironment()

    return ss

def local_path(*segments):
    # Service Code has no Core object (why not?), yet we need bundle_path
    bundle_path = inspect.getfile(inspect.currentframe())
    parents     = ['..'] * 4
    combined    = parents + list(segments)
    joined_path = os.path.join(bundle_path, *combined)

    return os.path.abspath(joined_path)

ss_logfile = local_path('ss.log')

def cleanup_old_libraries():
    import shutil
    def try_remove(path):
        try:
            if os.path.isdir(path):
                shutil.rmtree(path)
            elif os.path.exists(path):
                os.remove(path)
        except Exception, e:
            ss.util.print_exception(e)
            pass

    libraries_path = local_path('Contents', 'Libraries', 'Shared')
    ss_cache       = os.path.join(libraries_path, 'ss', 'cache_store')
    ss_env         = os.path.join(libraries_path, 'ss', 'environment')
    bridge_bridge  = os.path.join(libraries_path, 'bridge', 'bridge.py')
    bridge_cache   = os.path.join(libraries_path, 'bridge', 'cache_store')
    bridge_env     = os.path.join(libraries_path, 'bridge', 'environment')
    bridge_plex    = os.path.join(libraries_path, 'bridge', 'plex.py')
    bridge_user    = os.path.join(libraries_path, 'bridge', 'user.py')

    for path in (ss_env, ss_cache, bridge_bridge, bridge_cache, bridge_env,
            bridge_plex, bridge_user):
        try_remove(path)

def metadata_from(media):
    try:
        if 'episode' == media['_type']:
            obj = metadata_from_episode(media)

        elif 'movie' == media['_type']:
            obj = metadata_from_default(media, builder = MovieObject)

        merge_common_metadata(obj, media)
    except Exception, e:
        ss.util.log.exception(obj)
        obj = metadata_from_default(media)

    return obj

def metadata_from_default(media, builder = VideoClipObject):
    obj = builder(
        title = media.get('display_title'),
    )

    merge_common_metadata(obj, media)

    return obj

def merge_common_metadata(obj, media):
    overview        = media.get('display_overview', '')
    overview_parser = ur'^([\d\-]+) \u2014 ?(.*?)$'
    match_overview  = re.search(overview_parser, overview)
    obj.thumb       = media.get('artwork')

    if overview:
        if match_overview:
            air_date = Datetime.ParseDate(match_overview.group(1))
            overview = match_overview.group(2)

            obj.originally_available_at = air_date
            obj.summary = overview
        else:
            obj.summary = overview

def metadata_from_episode(media):
    finder_numbered = r'^(.+) (\d+)x(\d+) (.+)$'
    finder_dated    = r'^(.+): (.+) ([\d\.]+)'
    title           = media.get('display_title')

    match_numbered = re.search(finder_numbered, title)
    if match_numbered:
        return metadata_from_episode_numbered(media, match_numbered)

    match_dated = re.search(finder_dated, title)
    if match_dated:
        return metadata_from_episode_dated(media, match_dated)

def metadata_from_episode_numbered(media, match):
    obj            = EpisodeObject()
    show_title     = match.group(1)
    season_number  = int(match.group(2))
    episode_number = int(match.group(3))
    episode_title  = match.group(4)

    obj.show   = show_title
    obj.season = season_number
    obj.absolute_index = episode_number
    obj.title  = '%s. %s' % (episode_number, episode_title)

    return obj

def metadata_from_episode_dated(media, match):
    obj           = EpisodeObject()
    show_title    = match.group(1)
    air_date      = Datetime.ParseDate(match.group(3))
    episode_title = match.group(2)

    obj.show  = show_title
    obj.title = episode_title
    obj.originally_available_at = air_date

    return obj

from urlparse import urlparse
import cgi

class params(object):
    def __init__(self, url):
        nil, nil, path, nil, query, nil = urlparse(url)

        self.path   = path
        self.params = cgi.parse_qs(query)

    def get(self, key):
        return self.params[key][0]

    def getall(self, key):
        return self.params[key]
